{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as lr\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import logging\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib import pyplot  \n",
    "\n",
    "\n",
    "class VoiceSamples(Dataset):\n",
    "    \n",
    "    def __init__(self, core_name, samples_path=None, Automatic=None):\n",
    "        \n",
    "        self.Log = logging.getLogger()\n",
    "        #logging.basicConfig(level=logging.INFO)\n",
    "        \n",
    "        self.noiseThreshold = 1\n",
    "        \n",
    "        self.core_name = core_name\n",
    "        self.samples_path = samples_path\n",
    "        \n",
    "        self.soundSamples = []\n",
    "        self.sampleRate = []\n",
    "        self.path = []\n",
    "        \n",
    "        self.chopedSamples = []\n",
    "        self.chopedSr = []\n",
    "        \n",
    "        self.tensorMelgrams = []\n",
    "        \n",
    "        \n",
    "        self.info = \" VoiceSamples Object successfully created \"\n",
    "        self.Log.info(self.info)\n",
    "        \n",
    "        \n",
    "        if Automatic:\n",
    "            self.LoadSoundSamples()\n",
    "            self.ChopToOneSecFragments()\n",
    "            self.ChopedSignalsToTenosor()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tensorMelgrams)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.tensorMelgrams:\n",
    "            return self.tensorMelgrams[idx]\n",
    "\n",
    "    def LoadSoundSamples(self):\n",
    "    \n",
    "        n = 1\n",
    "\n",
    "        while(True):\n",
    "            try:\n",
    "                if  self.samples_path:\n",
    "                    path =  self.samples_path + self.core_name + str(n)\n",
    "                else:\n",
    "                    path = self.core_name + str(n)\n",
    "\n",
    "                soundSample, sampleRate = lr.load(path)\n",
    "\n",
    "                n += 1\n",
    "                self.soundSamples.append(soundSample)\n",
    "                self.sampleRate.append(sampleRate) \n",
    "                self.path.append(path)\n",
    "\n",
    "                self.info = \" Sample : \" + path + \" : successfully added\"\n",
    "                self.Log.info(self.info)\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                if self.soundSamples:\n",
    "                    self.info = \"That's the end of database : \" + str(n-1) + \" : Samples added\"\n",
    "                    self.Log.info(self.info)\n",
    "                    n = 0\n",
    "                    \n",
    "                    return self.soundSamples, self.sampleRate, self.path\n",
    "\n",
    "                else:\n",
    "                    self.Log.exception(\"Files are missing\")\n",
    "                    n = 0\n",
    "\n",
    "                break\n",
    "\n",
    "            except Exception as ex:      \n",
    "                self.Log.exception(\"Unexpected error\")\n",
    "                break\n",
    "        \n",
    "    def getSoundSample(self, idx):\n",
    "        return self.soundSamples[idx], self.sampleRate[idx]\n",
    "    \n",
    "    def getSoundSampleLen(self):\n",
    "        try:\n",
    "            if len(self.soundSamples) == len(self.sampleRate):\n",
    "                return len(self.soundSamples)\n",
    "            else:\n",
    "                self.Log.warning(\"Lists: sundSamples and sampleRate are not equal!\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.Log.exception(\"Unexpected error\" + e)\n",
    "    \n",
    "    def ChopToOneSecFragments(self):\n",
    "        \n",
    "        # TODO: make shure user goes step by step \n",
    "        \n",
    "        try:\n",
    "            if len(self.soundSamples) == len(self.sampleRate):\n",
    "                for idx in range(len(self.soundSamples)):\n",
    "                    \n",
    "                    soundSample = self.soundSamples[idx]\n",
    "                    sr = self.sampleRate[idx]\n",
    "                    \n",
    "                    frag_max = math.trunc(len(soundSample)/float(sr))\n",
    "                    step = math.trunc(sr/2);\n",
    "                    last_sample = len(soundSample)\n",
    "\n",
    "                    for frag in range(frag_max*2):\n",
    "                        start = step * frag\n",
    "                        stop = start + sr\n",
    "                        if sr<len(soundSample):\n",
    "                            if self.checkIfNotNoise(soundSample[start:stop]):\n",
    "                                self.chopedSamples.append(soundSample[start:stop])\n",
    "                                self.chopedSr.append(sr)\n",
    "                                self.info = self.path[idx] + \" : \" + str(frag+1) + \" : successfully choped\"\n",
    "                                self.Log.info(self.info)\n",
    "                            else:\n",
    "                                self.info = self.path[idx] + \" : \" + str(frag+1) + \" : NOISE!\"\n",
    "                                self.Log.info(self.info)\n",
    "                        else:\n",
    "                            self.Log.warning(\"Something went wrong\")\n",
    "                            \n",
    "                    if self.checkIfNotNoise(soundSample[last_sample-sr:last_sample]):\n",
    "                         # incuding samples cuted by math.trunc() \n",
    "                        self.chopedSamples.append(soundSample[last_sample-sr:last_sample])\n",
    "                        self.chopedSr.append(sr)\n",
    "                        self.info = self.path[idx] +  \" : \"  + str(frag_max*2+1) + \" : successfully choped\"\n",
    "                        self.Log.info(self.info)\n",
    "                    else:\n",
    "                        self.info = self.path[idx] + \" : \"  + str(frag+1) + \" : NOISE!\"\n",
    "                        self.Log.info(self.info)\n",
    "                \n",
    "                if self.chopedSamples:\n",
    "                    self.Log.info(\"Sucessfully choped all loaded signals and eliminated the noise!\")\n",
    "                    return self.chopedSamples, self.chopedSr \n",
    "                    \n",
    "            else:\n",
    "                self.Log.warning(\"Lists: sundSamples and sampleRate are not equal!\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.e = \"Unexpected error : \" + str(e)\n",
    "            self.Log.exception(self.e)\n",
    "            \n",
    "    def getChoped(self, idx):\n",
    "        return self.chopedSamples[idx], self.chopedSr[idx]\n",
    "        \n",
    "    def getChopedLen(self):\n",
    "        try:\n",
    "            if len(self.chopedSamples) == len(self.chopedSr):\n",
    "                    return len(self.chopedSamples)\n",
    "            else:\n",
    "                self.Log.warning(\"Lists: sundSamples and sampleRate are not equal!\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.Log.exception(\"Unexpected error\" + e)\n",
    "            \n",
    "        \n",
    "    def ChopedSignalsToTenosor(self):\n",
    "        \n",
    "        # TODO: make shure user goes step by step \n",
    "        \n",
    "        try:\n",
    "        \n",
    "            if len(self.chopedSamples) == len(self.chopedSr):\n",
    "                for idx in range(len(self.chopedSamples)):\n",
    "\n",
    "                    # hop length adjusted\n",
    "                    STFT_signal = np.abs(lr.stft(self.chopedSamples[idx], n_fft = 512, hop_length = round(self.chopedSr[idx]/256))) \n",
    "                    STFT_signal = lr.power_to_db(STFT_signal**2,ref=np.max)\n",
    "\n",
    "                    Melgram = STFT_signal[0:256,0:256]\n",
    "                    TMelgram = torch.tensor(Melgram)\n",
    "                    self.tensorMelgrams.append(TMelgram)\n",
    "                    \n",
    "                    self.info = \" \" + self.samples_path +  \" : ChopedSample \" + str(idx) + \" : \" + \" : converted to tensor\"\n",
    "                    self.Log.info(self.info)\n",
    "                \n",
    "                if self.tensorMelgrams:\n",
    "                    self.Log.info(\"Sucessfully converted all ChopedSamples to Tensors!\")\n",
    "                    return self.tensorMelgrams\n",
    "                \n",
    "            else:\n",
    "                self.Log.warning(\"Lists: chopedSamples and chopedSr are not equal!\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.e = \"Unexpected error : \" + str(e)\n",
    "            self.Log.exception(self.e)\n",
    "                \n",
    "    \n",
    "    \n",
    "    def checkIfNotNoise(self, chopedSample):\n",
    "    \n",
    "        chopedSamplePow2 = []\n",
    "\n",
    "        for n in range(len(chopedSample)):\n",
    "            chopedSamplePow2.append(chopedSample[n]**2)\n",
    "        sk = sum(chopedSamplePow2)\n",
    "        if sk > self.noiseThreshold:\n",
    "            return True \n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VoiceRecogModel(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=76880, out_features=2000, bias=True)\n",
       "  (fc2): Linear(in_features=2000, out_features=300, bias=True)\n",
       "  (fc3): Linear(in_features=300, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VoiceRecogModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VoiceRecogModel, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 10, 3)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(20*62*62, 2000)  # ?? from image dimension\n",
    "        self.fc2 = nn.Linear(2000, 300)\n",
    "        self.fc3 = nn.Linear(300, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "    # create parrter recognition model \n",
    "\n",
    "PATH = \"/home/krys/POLIBUDA/nn_VoiceRecognition_Models/modelV5.pt\"\n",
    "\n",
    "net = VoiceRecogModel()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proces weryfikacji nauczonej sieci Cz. 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vsNiciaTest2', 'vsNiciaTest1', 'vsKrystianTest1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# test sample folder view\n",
    "os.listdir(\"database/Test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krys/.local/lib/python3.7/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/krys/.local/lib/python3.7/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wynik rozpoznawania!\n",
      "Krystian: 39  Nicia: 1\n"
     ]
    }
   ],
   "source": [
    "# loading test samples of Krystians Voice\n",
    "vsTest = VoiceSamples(\"vsKrystianTest\", samples_path=\"database/Test/\" , Automatic=True)\n",
    "\n",
    "\n",
    "K = 0 # Recognizes as Krystian\n",
    "N = 0 # Recognizes as Nicia\n",
    "\n",
    "# Recognition loop\n",
    "\n",
    "for k in range(len(vsTest)):  \n",
    "    \n",
    "    vs = vsTest[k]\n",
    "    \n",
    "    input = vs.view(-1,1,256,256)\n",
    "    output = net(input)\n",
    "    v,i = output[0].max(0)\n",
    "    if int(i) == 0:\n",
    "        K += 1\n",
    "    else:\n",
    "        N += 1\n",
    "    \n",
    "print(\"Wynik rozpoznawania!\")\n",
    "print(\"Krystian:\",K,\" Nicia:\",N)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krys/.local/lib/python3.7/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/krys/.local/lib/python3.7/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/krys/.local/lib/python3.7/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wynik rozpoznawania!\n",
      "Krystian: 1  Nicia: 23\n"
     ]
    }
   ],
   "source": [
    "# loading test samples of Nicia's Voice\n",
    "vsTest = VoiceSamples(\"vsNiciaTest\", samples_path=\"database/Test/\" , Automatic=True)\n",
    "\n",
    "\n",
    "K = 0 # Recognizes as Krystian\n",
    "N = 0 # Recognizes as Nicia\n",
    "\n",
    "# Recognition loop\n",
    "\n",
    "for k in range(len(vsTest)):  \n",
    "    \n",
    "    vs = vsTest[k]\n",
    "    \n",
    "    input = vs.view(-1,1,256,256)\n",
    "    output = net(input)\n",
    "    v,i = output[0].max(0)\n",
    "    if int(i) == 0:\n",
    "        K += 1\n",
    "    else:\n",
    "        N += 1\n",
    "    \n",
    "print(\"Wynik rozpoznawania!\")\n",
    "print(\"Krystian:\",K,\" Nicia:\",N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
