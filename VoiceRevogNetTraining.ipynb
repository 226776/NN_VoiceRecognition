{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autor: Krystian Kasprów (indeks: 226776)\n",
    "\n",
    "# NN_VoiceRecognition\n",
    "\n",
    "System rozpozanwania głosu. Głównym założeniem jest rozpoznanie głosu założyciela projektu. \n",
    "Sieć będzie mieć zatem dwa wyjścia (jedno dla poprawnego rozpoznania głosu, drugie dla pozostałych dźwięków lub innej osoby). \n",
    "Jest to projekt treningowy mający na celu zaznajomienie się ze sztucznymi sieciami neuronowymi.\n",
    "Projekt realizowany jest przy użyciu narzędzi takich jak:\n",
    "- język programowania: Python 3\n",
    "- biblioteka obsługi dźwięku: librosa\n",
    "- biblioteka do sieci neuronowej: pytorch\n",
    "- środowisko projektu: jupyter notebook\n",
    "\n",
    "### Uwagi do projektu: \n",
    "- projekt prowadzony jest na github - link do repozytorium: https://github.com/226776/NN_VoiceRecognition\n",
    "- komentarze w kodzie w celu praktyki napisane są w języku angielskim\n",
    "\n",
    "### Tutorials (źródła wiedzy):\n",
    "\n",
    "- https://pytorch.org/tutorials/beginner/nn_tutorial.html (main)\n",
    "\n",
    "- https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py (main 2)\n",
    "\n",
    "- https://www.youtube.com/watch?v=LgFNRIFxuUo\n",
    "\n",
    "- https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proces uczenia Cz. 1\n",
    "## Klasa VoiceSamples\n",
    "\n",
    "Pierwszym krokiem jest przygotowanie danych wejściowych (nagrania z telefonu).\n",
    "Odpowiada za to klasa VoiceSamples.\n",
    "\n",
    "Metoda __LoadSoundSamples()__ : ładuje ona próbki o rdzeniu nazwy (__core_name__) iterując kolejno od jedynki.\n",
    "Domyślnie przeszukuje katalog projektu, możliwe jest określenie innej ścieżki poprzez podanie __smaples_path__.\n",
    "\n",
    "Metoda __ChopToOneSecFragments()__ : dzieli wczytane nagrania na jedno sekundowe \n",
    "fragmenty i dodaje je do tablicy wyników jeśli dane fragmenty nie są szumem. \n",
    "\n",
    "Metoda __ChopedSignalsToTenosor()__ : liczy transformatę __stft__ i przekształca ją na tensor o wymiarach __256x256__.\n",
    "Rozdzielczość dobrano eksperymentalnie oraz sprowadzono do najbliższej potęgi dwójki. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as lr\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import logging\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib import pyplot  \n",
    "\n",
    "\n",
    "class VoiceSamples(Dataset):\n",
    "    \n",
    "    def __init__(self, core_name, samples_path=None, Automatic=None):\n",
    "        \n",
    "        self.Log = logging.getLogger()\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        \n",
    "        self.noiseThreshold = 1\n",
    "        \n",
    "        self.core_name = core_name\n",
    "        self.samples_path = samples_path\n",
    "        \n",
    "        self.soundSamples = []\n",
    "        self.sampleRate = []\n",
    "        self.path = []\n",
    "        \n",
    "        self.chopedSamples = []\n",
    "        self.chopedSr = []\n",
    "        \n",
    "        self.tensorMelgrams = []\n",
    "        \n",
    "        \n",
    "        self.info = \" VoiceSamples Object successfully created \"\n",
    "        self.Log.info(self.info)\n",
    "        \n",
    "        \n",
    "        if Automatic:\n",
    "            self.LoadSoundSamples()\n",
    "            self.ChopToOneSecFragments()\n",
    "            self.ChopedSignalsToTenosor()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tensorMelgrams)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.tensorMelgrams:\n",
    "            return self.tensorMelgrams[idx]\n",
    "\n",
    "    def LoadSoundSamples(self):\n",
    "    \n",
    "        n = 1\n",
    "\n",
    "        while(True):\n",
    "            try:\n",
    "                if  self.samples_path:\n",
    "                    path =  self.samples_path + self.core_name + str(n)\n",
    "                else:\n",
    "                    path = self.core_name + str(n)\n",
    "\n",
    "                soundSample, sampleRate = lr.load(path)\n",
    "\n",
    "                n += 1\n",
    "                self.soundSamples.append(soundSample)\n",
    "                self.sampleRate.append(sampleRate) \n",
    "                self.path.append(path)\n",
    "\n",
    "                self.info = \" Sample : \" + path + \" : successfully added\"\n",
    "                self.Log.info(self.info)\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                if self.soundSamples:\n",
    "                    self.info = \"That's the end of database : \" + str(n-1) + \" : Samples added\"\n",
    "                    self.Log.info(self.info)\n",
    "                    n = 0\n",
    "                    \n",
    "                    return self.soundSamples, self.sampleRate, self.path\n",
    "\n",
    "                else:\n",
    "                    self.Log.exception(\"Files are missing\")\n",
    "                    n = 0\n",
    "\n",
    "                break\n",
    "\n",
    "            except Exception as ex:      \n",
    "                self.Log.exception(\"Unexpected error\")\n",
    "                break\n",
    "        \n",
    "    def getSoundSample(self, idx):\n",
    "        return self.soundSamples[idx], self.sampleRate[idx]\n",
    "    \n",
    "    def getSoundSampleLen(self):\n",
    "        try:\n",
    "            if len(self.soundSamples) == len(self.sampleRate):\n",
    "                return len(self.soundSamples)\n",
    "            else:\n",
    "                self.Log.warning(\"Lists: sundSamples and sampleRate are not equal!\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.Log.exception(\"Unexpected error\" + e)\n",
    "    \n",
    "    def ChopToOneSecFragments(self):\n",
    "        \n",
    "        # TODO: make shure user goes step by step \n",
    "        \n",
    "        try:\n",
    "            if len(self.soundSamples) == len(self.sampleRate):\n",
    "                for idx in range(len(self.soundSamples)):\n",
    "                    \n",
    "                    soundSample = self.soundSamples[idx]\n",
    "                    sr = self.sampleRate[idx]\n",
    "                    \n",
    "                    frag_max = math.trunc(len(soundSample)/float(sr))\n",
    "                    step = math.trunc(sr/2);\n",
    "                    last_sample = len(soundSample)\n",
    "\n",
    "                    for frag in range(frag_max*2):\n",
    "                        start = step * frag\n",
    "                        stop = start + sr\n",
    "                        if sr<len(soundSample):\n",
    "                            if self.checkIfNotNoise(soundSample[start:stop]):\n",
    "                                self.chopedSamples.append(soundSample[start:stop])\n",
    "                                self.chopedSr.append(sr)\n",
    "                                self.info = self.path[idx] + \" : \" + str(frag+1) + \" : successfully choped\"\n",
    "                                self.Log.info(self.info)\n",
    "                            else:\n",
    "                                self.info = self.path[idx] + \" : \" + str(frag+1) + \" : NOISE!\"\n",
    "                                self.Log.info(self.info)\n",
    "                        else:\n",
    "                            self.Log.warning(\"Something went wrong\")\n",
    "                            \n",
    "                    if self.checkIfNotNoise(soundSample[last_sample-sr:last_sample]):\n",
    "                         # incuding samples cuted by math.trunc() \n",
    "                        self.chopedSamples.append(soundSample[last_sample-sr:last_sample])\n",
    "                        self.chopedSr.append(sr)\n",
    "                        self.info = self.path[idx] +  \" : \"  + str(frag_max*2+1) + \" : successfully choped\"\n",
    "                        self.Log.info(self.info)\n",
    "                    else:\n",
    "                        self.info = self.path[idx] + \" : \"  + str(frag+1) + \" : NOISE!\"\n",
    "                        self.Log.info(self.info)\n",
    "                \n",
    "                if self.chopedSamples:\n",
    "                    self.Log.info(\"Sucessfully choped all loaded signals and eliminated the noise!\")\n",
    "                    return self.chopedSamples, self.chopedSr \n",
    "                    \n",
    "            else:\n",
    "                self.Log.warning(\"Lists: sundSamples and sampleRate are not equal!\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.e = \"Unexpected error : \" + str(e)\n",
    "            self.Log.exception(self.e)\n",
    "            \n",
    "    def getChoped(self, idx):\n",
    "        return self.chopedSamples[idx], self.chopedSr[idx]\n",
    "        \n",
    "    def getChopedLen(self):\n",
    "        try:\n",
    "            if len(self.chopedSamples) == len(self.chopedSr):\n",
    "                    return len(self.chopedSamples)\n",
    "            else:\n",
    "                self.Log.warning(\"Lists: sundSamples and sampleRate are not equal!\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.Log.exception(\"Unexpected error\" + e)\n",
    "            \n",
    "        \n",
    "    def ChopedSignalsToTenosor(self):\n",
    "        \n",
    "        # TODO: make shure user goes step by step \n",
    "        \n",
    "        try:\n",
    "        \n",
    "            if len(self.chopedSamples) == len(self.chopedSr):\n",
    "                for idx in range(len(self.chopedSamples)):\n",
    "\n",
    "                    # hop length adjusted\n",
    "                    STFT_signal = np.abs(lr.stft(self.chopedSamples[idx], n_fft = 512, hop_length = round(self.chopedSr[idx]/256))) \n",
    "                    STFT_signal = lr.power_to_db(STFT_signal**2,ref=np.max)\n",
    "\n",
    "                    Melgram = STFT_signal[0:256,0:256]\n",
    "                    TMelgram = torch.tensor(Melgram)\n",
    "                    self.tensorMelgrams.append(TMelgram)\n",
    "                    \n",
    "                    self.info = \" \" + self.samples_path +  \" : ChopedSample \" + str(idx) + \" : \" + \" : converted to tensor\"\n",
    "                    self.Log.info(self.info)\n",
    "                \n",
    "                if self.tensorMelgrams:\n",
    "                    self.Log.info(\"Sucessfully converted all ChopedSamples to Tensors!\")\n",
    "                    return self.tensorMelgrams\n",
    "                \n",
    "            else:\n",
    "                self.Log.warning(\"Lists: chopedSamples and chopedSr are not equal!\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.e = \"Unexpected error : \" + str(e)\n",
    "            self.Log.exception(self.e)\n",
    "                \n",
    "    \n",
    "    \n",
    "    def checkIfNotNoise(self, chopedSample):\n",
    "    \n",
    "        chopedSamplePow2 = []\n",
    "\n",
    "        for n in range(len(chopedSample)):\n",
    "            chopedSamplePow2.append(chopedSample[n]**2)\n",
    "        sk = sum(chopedSamplePow2)\n",
    "        if sk > self.noiseThreshold:\n",
    "            return True \n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasa VoiceSamplesInput()\n",
    "\n",
    "Klasa wykorzystuje wyżej opisaną klasę __VoiceSamples()__ do załadowania próbek dwóch ludzi oraz przypisania im odpowiedniego spodziewanego wyniku (__target__).\n",
    "\n",
    "Sieć neuronowa nie powinna uczyć się zbyt uporządkowanych danych, dlatego też dane dwóch osób są podawane naprzemiennnie. \n",
    "Klasa dla wejściowego indeksu parzystego zwraca próbki osoby pierwszej, dla nieparzystego natomiast osoby drugiej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class VoiceSamplesInput():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # load voice samples of Krystian\n",
    "        self.vsKrystian = VoiceSamples(\"vsKrystian\", samples_path=\"database/Krystian/\" , Automatic=True)\n",
    "        # load voice samples of Nicia\n",
    "        self.vsNicia = VoiceSamples(\"vsNicia\", samples_path=\"database/Nicia/\" , Automatic=True)\n",
    "        \n",
    "        # expected output - target of Krystian\n",
    "        self.targetKrystian = torch.tensor([[float(1),float(0)]])\n",
    "        # expected output - target of Nicia\n",
    "        self.targetNicia = torch.tensor([[float(0),float(1)]])\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if idx % 2 == 0:\n",
    "            return self.vsKrystian[int(idx/2)] ,  self.targetKrystian\n",
    "        else:\n",
    "            return self.vsNicia[int((idx+1)/2)] , self.targetNicia\n",
    "    \n",
    "    def __len__(self):\n",
    "        if len(self.vsKrystian) <= len(self.vsNicia):\n",
    "            return len(self.vsKrystian) * 2\n",
    "        else:\n",
    "            return len(self.vsNicia) * 2\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VoiceRecogModel\n",
    "\n",
    "Model sieci neuronowej wykorzystywany do reazlizacji klasyfikacji rozpoznania właściciela nagranego głosu. \n",
    "\n",
    "Model składa się z pięciu warstw ukrytych (nie licząc tzw. pooling'u) :\n",
    "- dwie warstwy splotowe (convolutional): __conv1d__, __conv2d__\n",
    "- trzy warstwy w pełni połączone (fully connected): __fc1__, __fc2__, __fc3__\n",
    "\n",
    "Dane na wyjściu warstw splotowych są redukowane dwukrotnie przy zachowaniu, \n",
    "czy też nawet wzmocnieniu najważniejszych cehch przy użyciu funkcji __F.max_pool2d()__. \n",
    "\n",
    "Funkcją aktywacji jest funkcja __F.relu()__.\n",
    "\n",
    "Model przeliczony jest dla jednego tensora wejściowego o wymiarach __256x256__. \n",
    "W praktyce oznacza to zbadanie/wyliczenie wymiarów pojedynczego wyjścia warstwy __conv2d (62x62)__.\n",
    "Wejście kolejenej warstwy  __fc1__ jest więc iloczynem wymiarów pojedynczego wyjścia oraz ilością kanałów (__20__).\n",
    "\n",
    "Sieć z racji realizowanego zadania ma jedynie 2 wyjścia __fc3__. \n",
    "\n",
    "Metoda __forward(self, x)__ relizuje przeliczenie pojedynczego obiektu wejsciowego na oczekiwane wyjście. \n",
    "\n",
    "Uwaga! Wszystkie parametry sieci zostały dobrane eksperymentalnie w oparciu o przykłady oraz zasadę, że ilość neuronów w warstwie powinna być pomiędzy ilościami neuronów w warstwach sąsiednich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VoiceRecogModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VoiceRecogModel, self).__init__()\n",
    "        # 1 input image channel, 10 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 10, 3)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(20*62*62, 2000)  # 20: Conv2d output channel number, 62x62: Conv2d one channel image\n",
    "        self.fc2 = nn.Linear(2000, 300)\n",
    "        self.fc3 = nn.Linear(300, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tym miejscu tworzona jest baza do uczenia sieci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create dataset : loading and processing samples to tensors\n",
    "vsInput = VoiceSamplesInput()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tym miejscu tworzony jest model sieci, funkcja strat oraz funkcja realizująca wsteczną propagację (__optimizer__).\n",
    "\n",
    "Krytycznym jest odpowiednie dobranie prametru __lr__ określającego wpływ każdej iteracji na korekcję wag.\n",
    "Im większy __lr__, tym większa korekta. \n",
    "Zbyt duży __lr__ powodują, iż wyjście będzie zbiegać do nieskonczoności lub sieć będzie rozpoznawać jedynie kilka - kilkanaście ostatnich obiektów wejściowych.\n",
    "Zbyt mały __lr__, spowoduje, że sieć do nauki będzie wymagała ogromną ilość danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create net from VoiceRecogModel\n",
    "net = VoiceRecogModel()\n",
    "\n",
    "# loss function (using function implemented in pytorch)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# create your optimizer (basic optimizer)\n",
    "# setting learning rate \n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preces uczenia (realizowany poniżej) polega na :\n",
    "    - wyliczeniu wyjścia dla pobranej z bazy próbki (__vs, target = vsInput[k]__)\n",
    "    - wyliczeniu straty, czyli różnicy pomiędzy wyjściem a oczekiwaniami (__loss = criterion(output, target)__)\n",
    "    - wyliczeniu tzw. biasu, czyli wartości o jakie skorygowane mają zostać wagi (__loss.backward()__)\n",
    "    - zaktualizowaniu wag\n",
    "    \n",
    "Proces ten powtarzany jest dla wszystkich elementów bazy. Przy użyciu tej samej bazy można uczyć klika razy (np. __epoch = 2__).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "trainLog = logging.getLogger()\n",
    "\n",
    "# Training Loop\n",
    "\n",
    "# How many times learn on the same dataset\n",
    "epoch = 1\n",
    "for i in range(epoch):   \n",
    "    for k in range(len(vsInput)):  \n",
    "        try:\n",
    "            vs, target = vsInput[k]\n",
    "\n",
    "            optimizer.zero_grad()   # zero the gradient buffers\n",
    "            input = vs.view(-1,1,256,256)\n",
    "            output = net(input)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()    # Does the update\n",
    "\n",
    "\n",
    "            info = \"Training \" + str(k)+\"/\"+str(len(vsInput))+\" done\"\n",
    "\n",
    "            print(\"\\n\")\n",
    "            print(target)\n",
    "            print(output)\n",
    "            print(loss)\n",
    "            print(info)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zapisanie modelu sieci na dysku lokalnym. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
