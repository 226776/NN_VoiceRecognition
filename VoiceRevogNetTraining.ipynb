{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as lr\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import logging\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib import pyplot  \n",
    "\n",
    "\n",
    "class VoiceSamples(Dataset):\n",
    "    \n",
    "    def __init__(self, core_name, samples_path=None, Automatic=None):\n",
    "        \n",
    "        self.Log = logging.getLogger()\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        \n",
    "        self.noiseThreshold = 1\n",
    "        \n",
    "        self.core_name = core_name\n",
    "        self.samples_path = samples_path\n",
    "        \n",
    "        self.soundSamples = []\n",
    "        self.sampleRate = []\n",
    "        self.path = []\n",
    "        \n",
    "        self.chopedSamples = []\n",
    "        self.chopedSr = []\n",
    "        \n",
    "        self.tensorMelgrams = []\n",
    "        \n",
    "        \n",
    "        self.info = \" VoiceSamples Object successfully created \"\n",
    "        self.Log.info(self.info)\n",
    "        \n",
    "        \n",
    "        if Automatic:\n",
    "            self.LoadSoundSamples()\n",
    "            self.ChopToOneSecFragments()\n",
    "            self.ChopedSignalsToTenosor()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tensorMelgrams)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.tensorMelgrams:\n",
    "            return self.tensorMelgrams[idx]\n",
    "\n",
    "    def LoadSoundSamples(self):\n",
    "    \n",
    "        n = 1\n",
    "\n",
    "        while(True):\n",
    "            try:\n",
    "                if  self.samples_path:\n",
    "                    path =  self.samples_path + self.core_name + str(n)\n",
    "                else:\n",
    "                    path = self.core_name + str(n)\n",
    "\n",
    "                soundSample, sampleRate = lr.load(path)\n",
    "\n",
    "                n += 1\n",
    "                self.soundSamples.append(soundSample)\n",
    "                self.sampleRate.append(sampleRate) \n",
    "                self.path.append(path)\n",
    "\n",
    "                self.info = \" Sample : \" + path + \" : successfully added\"\n",
    "                self.Log.info(self.info)\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                if self.soundSamples:\n",
    "                    self.info = \"That's the end of database : \" + str(n-1) + \" : Samples added\"\n",
    "                    self.Log.info(self.info)\n",
    "                    n = 0\n",
    "                    \n",
    "                    return self.soundSamples, self.sampleRate, self.path\n",
    "\n",
    "                else:\n",
    "                    self.Log.exception(\"Files are missing\")\n",
    "                    n = 0\n",
    "\n",
    "                break\n",
    "\n",
    "            except Exception as ex:      \n",
    "                self.Log.exception(\"Unexpected error\")\n",
    "                break\n",
    "        \n",
    "    def getSoundSample(self, idx):\n",
    "        return self.soundSamples[idx], self.sampleRate[idx]\n",
    "    \n",
    "    def getSoundSampleLen(self):\n",
    "        try:\n",
    "            if len(self.soundSamples) == len(self.sampleRate):\n",
    "                return len(self.soundSamples)\n",
    "            else:\n",
    "                self.Log.warning(\"Lists: sundSamples and sampleRate are not equal!\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.Log.exception(\"Unexpected error\" + e)\n",
    "    \n",
    "    def ChopToOneSecFragments(self):\n",
    "        \n",
    "        # TODO: make shure user goes step by step \n",
    "        \n",
    "        try:\n",
    "            if len(self.soundSamples) == len(self.sampleRate):\n",
    "                for idx in range(len(self.soundSamples)):\n",
    "                    \n",
    "                    soundSample = self.soundSamples[idx]\n",
    "                    sr = self.sampleRate[idx]\n",
    "                    \n",
    "                    frag_max = math.trunc(len(soundSample)/float(sr))\n",
    "                    step = math.trunc(sr/2);\n",
    "                    last_sample = len(soundSample)\n",
    "\n",
    "                    for frag in range(frag_max*2):\n",
    "                        start = step * frag\n",
    "                        stop = start + sr\n",
    "                        if sr<len(soundSample):\n",
    "                            if self.checkIfNotNoise(soundSample[start:stop]):\n",
    "                                self.chopedSamples.append(soundSample[start:stop])\n",
    "                                self.chopedSr.append(sr)\n",
    "                                self.info = self.path[idx] + \" : \" + str(frag+1) + \" : successfully choped\"\n",
    "                                self.Log.info(self.info)\n",
    "                            else:\n",
    "                                self.info = self.path[idx] + \" : \" + str(frag+1) + \" : NOISE!\"\n",
    "                                self.Log.info(self.info)\n",
    "                        else:\n",
    "                            self.Log.warning(\"Something went wrong\")\n",
    "                            \n",
    "                    if self.checkIfNotNoise(soundSample[last_sample-sr:last_sample]):\n",
    "                         # incuding samples cuted by math.trunc() \n",
    "                        self.chopedSamples.append(soundSample[last_sample-sr:last_sample])\n",
    "                        self.chopedSr.append(sr)\n",
    "                        self.info = self.path[idx] +  \" : \"  + str(frag_max*2+1) + \" : successfully choped\"\n",
    "                        self.Log.info(self.info)\n",
    "                    else:\n",
    "                        self.info = self.path[idx] + \" : \"  + str(frag+1) + \" : NOISE!\"\n",
    "                        self.Log.info(self.info)\n",
    "                \n",
    "                if self.chopedSamples:\n",
    "                    self.Log.info(\"Sucessfully choped all loaded signals and eliminated the noise!\")\n",
    "                    return self.chopedSamples, self.chopedSr \n",
    "                    \n",
    "            else:\n",
    "                self.Log.warning(\"Lists: sundSamples and sampleRate are not equal!\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.e = \"Unexpected error : \" + str(e)\n",
    "            self.Log.exception(self.e)\n",
    "            \n",
    "    def getChoped(self, idx):\n",
    "        return self.chopedSamples[idx], self.chopedSr[idx]\n",
    "        \n",
    "    def getChopedLen(self):\n",
    "        try:\n",
    "            if len(self.chopedSamples) == len(self.chopedSr):\n",
    "                    return len(self.chopedSamples)\n",
    "            else:\n",
    "                self.Log.warning(\"Lists: sundSamples and sampleRate are not equal!\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.Log.exception(\"Unexpected error\" + e)\n",
    "            \n",
    "        \n",
    "    def ChopedSignalsToTenosor(self):\n",
    "        \n",
    "        # TODO: make shure user goes step by step \n",
    "        \n",
    "        try:\n",
    "        \n",
    "            if len(self.chopedSamples) == len(self.chopedSr):\n",
    "                for idx in range(len(self.chopedSamples)):\n",
    "\n",
    "                    # hop length adjusted\n",
    "                    STFT_signal = np.abs(lr.stft(self.chopedSamples[idx], n_fft = 512, hop_length = round(self.chopedSr[idx]/256))) \n",
    "                    STFT_signal = lr.power_to_db(STFT_signal**2,ref=np.max)\n",
    "\n",
    "                    Melgram = STFT_signal[0:256,0:256]\n",
    "                    TMelgram = torch.tensor(Melgram)\n",
    "                    self.tensorMelgrams.append(TMelgram)\n",
    "                    \n",
    "                    self.info = \" \" + self.samples_path +  \" : ChopedSample \" + str(idx) + \" : \" + \" : converted to tensor\"\n",
    "                    self.Log.info(self.info)\n",
    "                \n",
    "                if self.tensorMelgrams:\n",
    "                    self.Log.info(\"Sucessfully converted all ChopedSamples to Tensors!\")\n",
    "                    return self.tensorMelgrams\n",
    "                \n",
    "            else:\n",
    "                self.Log.warning(\"Lists: chopedSamples and chopedSr are not equal!\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.e = \"Unexpected error : \" + str(e)\n",
    "            self.Log.exception(self.e)\n",
    "                \n",
    "    \n",
    "    \n",
    "    def checkIfNotNoise(self, chopedSample):\n",
    "    \n",
    "        chopedSamplePow2 = []\n",
    "\n",
    "        for n in range(len(chopedSample)):\n",
    "            chopedSamplePow2.append(chopedSample[n]**2)\n",
    "        sk = sum(chopedSamplePow2)\n",
    "        if sk > self.noiseThreshold:\n",
    "            return True \n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use torch.save(tensor, 'file.pt') and torch.load('file.pt')\n",
    "\n",
    "class VoiceSamplesInput():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.vsKrystian = VoiceSamples(\"vsKrystian\", samples_path=\"database/Krystian/\" , Automatic=True)\n",
    "        self.vsNicia = VoiceSamples(\"vsNicia\", samples_path=\"database/Nicia/\" , Automatic=True)\n",
    "\n",
    "        self.targetKrystian = torch.tensor([[float(1),float(0)]])\n",
    "        self.targetNicia = torch.tensor([[float(0),float(1)]])\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if idx % 2 == 0:\n",
    "            return self.vsKrystian[int(idx/2)] ,  self.targetKrystian\n",
    "        else:\n",
    "            return self.vsNicia[int((idx+1)/2)] , self.targetNicia\n",
    "    \n",
    "    def __len__(self):\n",
    "        if len(self.vsKrystian) <= len(self.vsNicia):\n",
    "            return len(self.vsKrystian) * 2\n",
    "        else:\n",
    "            return len(self.vsNicia) * 2\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VoiceRecogModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VoiceRecogModel, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16*62*62, 120)  # ?? from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: VoiceSamples Object successfully created \n",
      "/home/krys/.local/lib/python3.7/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "INFO:root: Sample : database/Krystian/vsKrystian1 : successfully added\n",
      "/home/krys/.local/lib/python3.7/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "INFO:root: Sample : database/Krystian/vsKrystian2 : successfully added\n",
      "/home/krys/.local/lib/python3.7/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "INFO:root:That's the end of database : 2 : Samples added\n",
      "INFO:root:database/Krystian/vsKrystian1 : 1 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian1 : 2 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian1 : 3 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian1 : 4 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian1 : 5 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian1 : 6 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian1 : 7 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian1 : 8 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian1 : 9 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian1 : 10 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian1 : 11 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian1 : 12 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian1 : 13 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian1 : 14 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian1 : 15 : NOISE!\n",
      "INFO:root:database/Krystian/vsKrystian1 : 16 : NOISE!\n",
      "INFO:root:database/Krystian/vsKrystian1 : 17 : NOISE!\n",
      "INFO:root:database/Krystian/vsKrystian1 : 18 : NOISE!\n",
      "INFO:root:database/Krystian/vsKrystian1 : 18 : NOISE!\n",
      "INFO:root:database/Krystian/vsKrystian2 : 1 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 2 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 3 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 4 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 5 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 6 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 7 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 8 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 9 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 10 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 11 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 12 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 13 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 14 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 15 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 16 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 17 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 18 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 19 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 20 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 21 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 22 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 23 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 24 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 25 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 26 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 27 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 28 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 29 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 30 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 31 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 32 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 33 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 34 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 35 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 36 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 37 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 38 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 39 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 40 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 41 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 42 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 43 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 44 : NOISE!\n",
      "INFO:root:database/Krystian/vsKrystian2 : 45 : NOISE!\n",
      "INFO:root:database/Krystian/vsKrystian2 : 46 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 47 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 48 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 49 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 50 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 51 : NOISE!\n",
      "INFO:root:database/Krystian/vsKrystian2 : 52 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 53 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 54 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 55 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 56 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 57 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 58 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 59 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 60 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 61 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 62 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 63 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 64 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 65 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 66 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 67 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 68 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 69 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 70 : NOISE!\n",
      "INFO:root:database/Krystian/vsKrystian2 : 71 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 72 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 73 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 74 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 75 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 76 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 77 : NOISE!\n",
      "INFO:root:database/Krystian/vsKrystian2 : 78 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 79 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 80 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 81 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 82 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 83 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 84 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 85 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 86 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 87 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 88 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 89 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 90 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 91 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 92 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 93 : successfully choped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:database/Krystian/vsKrystian2 : 94 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 95 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 96 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 97 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 98 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 99 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 100 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 101 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 102 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 103 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 104 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 105 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 106 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 107 : NOISE!\n",
      "INFO:root:database/Krystian/vsKrystian2 : 108 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 109 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 110 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 111 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 112 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 113 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 114 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 115 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 116 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 117 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 118 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 119 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 120 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 121 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 122 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 123 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 124 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 125 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 126 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 127 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 128 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 129 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 130 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 131 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 132 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 133 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 134 : successfully choped\n",
      "INFO:root:database/Krystian/vsKrystian2 : 135 : successfully choped\n",
      "INFO:root:Sucessfully choped all loaded signals and eliminated the noise!\n",
      "INFO:root: database/Krystian/ : ChopedSample 0 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 1 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 2 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 3 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 4 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 5 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 6 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 7 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 8 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 9 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 10 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 11 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 12 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 13 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 14 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 15 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 16 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 17 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 18 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 19 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 20 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 21 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 22 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 23 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 24 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 25 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 26 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 27 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 28 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 29 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 30 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 31 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 32 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 33 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 34 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 35 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 36 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 37 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 38 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 39 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 40 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 41 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 42 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 43 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 44 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 45 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 46 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 47 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 48 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 49 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 50 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 51 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 52 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 53 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 54 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 55 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 56 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 57 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 58 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 59 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 60 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 61 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 62 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 63 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 64 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 65 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 66 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 67 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 68 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 69 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 70 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 71 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 72 :  : converted to tensor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: database/Krystian/ : ChopedSample 73 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 74 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 75 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 76 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 77 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 78 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 79 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 80 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 81 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 82 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 83 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 84 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 85 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 86 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 87 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 88 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 89 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 90 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 91 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 92 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 93 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 94 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 95 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 96 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 97 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 98 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 99 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 100 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 101 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 102 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 103 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 104 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 105 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 106 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 107 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 108 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 109 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 110 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 111 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 112 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 113 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 114 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 115 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 116 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 117 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 118 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 119 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 120 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 121 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 122 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 123 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 124 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 125 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 126 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 127 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 128 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 129 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 130 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 131 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 132 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 133 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 134 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 135 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 136 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 137 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 138 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 139 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 140 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 141 :  : converted to tensor\n",
      "INFO:root: database/Krystian/ : ChopedSample 142 :  : converted to tensor\n",
      "INFO:root:Sucessfully converted all ChopedSamples to Tensors!\n",
      "INFO:root: VoiceSamples Object successfully created \n",
      "/home/krys/.local/lib/python3.7/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "INFO:root: Sample : database/Nicia/vsNicia1 : successfully added\n",
      "/home/krys/.local/lib/python3.7/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "INFO:root: Sample : database/Nicia/vsNicia2 : successfully added\n",
      "/home/krys/.local/lib/python3.7/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "INFO:root:That's the end of database : 2 : Samples added\n",
      "INFO:root:database/Nicia/vsNicia1 : 1 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 2 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 3 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 4 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 5 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 6 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 7 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 8 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 9 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 10 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 11 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 12 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 13 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 14 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 15 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 16 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 17 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 18 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 19 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 20 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 21 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 22 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 23 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 24 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 25 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 26 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 27 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 28 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 29 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 30 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 31 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 32 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 33 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 34 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 35 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 36 : successfully choped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:database/Nicia/vsNicia1 : 37 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 38 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 39 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 40 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 41 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 42 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 43 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 44 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 45 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 46 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 47 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 48 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 49 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 50 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 51 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 52 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 53 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 54 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 55 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 56 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 57 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 58 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 59 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 60 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 61 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 62 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 63 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 64 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 65 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 66 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 67 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 68 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 69 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 70 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 71 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 72 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 73 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 74 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 75 : NOISE!\n",
      "INFO:root:database/Nicia/vsNicia1 : 76 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 77 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 78 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia1 : 78 : NOISE!\n",
      "INFO:root:database/Nicia/vsNicia2 : 1 : NOISE!\n",
      "INFO:root:database/Nicia/vsNicia2 : 2 : NOISE!\n",
      "INFO:root:database/Nicia/vsNicia2 : 3 : NOISE!\n",
      "INFO:root:database/Nicia/vsNicia2 : 4 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 5 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 6 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 7 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 8 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 9 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 10 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 11 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 12 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 13 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 14 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 15 : NOISE!\n",
      "INFO:root:database/Nicia/vsNicia2 : 16 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 17 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 18 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 19 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 20 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 21 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 22 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 23 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 24 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 25 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 26 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 27 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 28 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 29 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 30 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 31 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 32 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 33 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 34 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 35 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 36 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 37 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 38 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 39 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 40 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 41 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 42 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 43 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 44 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 45 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 46 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 47 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 48 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 49 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 50 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 51 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 52 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 53 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 54 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 55 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 56 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 57 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 58 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 59 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 60 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 61 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 62 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 63 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 64 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 65 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 66 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 67 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 68 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 69 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 70 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 71 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 72 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 73 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 74 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 75 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 76 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 77 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 78 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 79 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 80 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 81 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 82 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 83 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 84 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 85 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 86 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 87 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 88 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 89 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 90 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 91 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 92 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 93 : successfully choped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:database/Nicia/vsNicia2 : 94 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 95 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 96 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 97 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 98 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 99 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 100 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 101 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 102 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 103 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 104 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 105 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 106 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 107 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 108 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 109 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 110 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 111 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 112 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 113 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 114 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 115 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 116 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 117 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 118 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 119 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 120 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 121 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 122 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 123 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 124 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 125 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 126 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 127 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 128 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 129 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 130 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 131 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 132 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 133 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 134 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 135 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 136 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 137 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 138 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 139 : NOISE!\n",
      "INFO:root:database/Nicia/vsNicia2 : 140 : NOISE!\n",
      "INFO:root:database/Nicia/vsNicia2 : 141 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 142 : NOISE!\n",
      "INFO:root:database/Nicia/vsNicia2 : 143 : NOISE!\n",
      "INFO:root:database/Nicia/vsNicia2 : 144 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 145 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 146 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 147 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 148 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 149 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 150 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 151 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 152 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 153 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 154 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 155 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 156 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 157 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 158 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 159 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 160 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 161 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 162 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 163 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 164 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 165 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 166 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 167 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 168 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 169 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 170 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 171 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 172 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 173 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 174 : NOISE!\n",
      "INFO:root:database/Nicia/vsNicia2 : 175 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 176 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 177 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 178 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 179 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 180 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 181 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 182 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 183 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 184 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 185 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 186 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 187 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 188 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 189 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 190 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 191 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 192 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 193 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 194 : successfully choped\n",
      "INFO:root:database/Nicia/vsNicia2 : 195 : successfully choped\n",
      "INFO:root:Sucessfully choped all loaded signals and eliminated the noise!\n",
      "INFO:root: database/Nicia/ : ChopedSample 0 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 1 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 2 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 3 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 4 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 5 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 6 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 7 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 8 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 9 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 10 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 11 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 12 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 13 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 14 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 15 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 16 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 17 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 18 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 19 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 20 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 21 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 22 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 23 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 24 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 25 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 26 :  : converted to tensor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: database/Nicia/ : ChopedSample 27 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 28 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 29 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 30 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 31 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 32 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 33 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 34 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 35 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 36 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 37 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 38 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 39 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 40 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 41 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 42 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 43 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 44 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 45 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 46 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 47 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 48 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 49 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 50 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 51 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 52 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 53 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 54 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 55 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 56 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 57 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 58 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 59 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 60 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 61 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 62 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 63 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 64 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 65 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 66 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 67 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 68 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 69 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 70 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 71 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 72 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 73 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 74 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 75 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 76 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 77 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 78 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 79 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 80 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 81 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 82 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 83 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 84 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 85 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 86 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 87 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 88 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 89 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 90 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 91 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 92 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 93 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 94 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 95 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 96 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 97 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 98 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 99 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 100 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 101 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 102 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 103 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 104 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 105 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 106 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 107 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 108 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 109 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 110 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 111 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 112 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 113 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 114 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 115 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 116 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 117 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 118 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 119 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 120 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 121 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 122 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 123 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 124 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 125 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 126 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 127 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 128 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 129 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 130 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 131 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 132 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 133 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 134 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 135 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 136 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 137 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 138 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 139 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 140 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 141 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 142 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 143 :  : converted to tensor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: database/Nicia/ : ChopedSample 144 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 145 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 146 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 147 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 148 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 149 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 150 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 151 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 152 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 153 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 154 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 155 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 156 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 157 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 158 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 159 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 160 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 161 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 162 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 163 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 164 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 165 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 166 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 167 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 168 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 169 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 170 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 171 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 172 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 173 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 174 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 175 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 176 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 177 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 178 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 179 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 180 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 181 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 182 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 183 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 184 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 185 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 186 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 187 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 188 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 189 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 190 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 191 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 192 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 193 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 194 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 195 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 196 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 197 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 198 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 199 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 200 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 201 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 202 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 203 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 204 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 205 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 206 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 207 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 208 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 209 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 210 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 211 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 212 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 213 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 214 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 215 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 216 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 217 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 218 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 219 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 220 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 221 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 222 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 223 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 224 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 225 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 226 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 227 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 228 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 229 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 230 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 231 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 232 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 233 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 234 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 235 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 236 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 237 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 238 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 239 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 240 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 241 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 242 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 243 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 244 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 245 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 246 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 247 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 248 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 249 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 250 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 251 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 252 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 253 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 254 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 255 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 256 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 257 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 258 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 259 :  : converted to tensor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: database/Nicia/ : ChopedSample 260 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 261 :  : converted to tensor\n",
      "INFO:root: database/Nicia/ : ChopedSample 262 :  : converted to tensor\n",
      "INFO:root:Sucessfully converted all ChopedSamples to Tensors!\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create dataset : loading and processing samples to tensors\n",
    "vsInput = VoiceSamplesInput()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create net from VoiceRecogModel\n",
    "net = VoiceRecogModel()\n",
    "\n",
    "# loss function (using function implemented in pytorch)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# create your optimizer (basic optimizer)\n",
    "# setting learning rate \n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 0/286 done\n",
      "INFO:root:Training 1/286 done\n",
      "INFO:root:Training 2/286 done\n",
      "INFO:root:Training 3/286 done\n",
      "INFO:root:Training 4/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[ 0.1377, -0.0440]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.3728, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[ 0.2048, -0.0287]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.5500, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.1923, 0.0625]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.3282, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.2555, 0.0746]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.4609, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.2585, 0.1755]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2903, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 5/286 done\n",
      "INFO:root:Training 6/286 done\n",
      "INFO:root:Training 7/286 done\n",
      "INFO:root:Training 8/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.3211, 0.1603]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.4041, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.3146, 0.2921]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2775, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.3738, 0.2599]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.3437, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.3617, 0.3858]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2781, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.4276, 0.3329]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.3140, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 9/286 done\n",
      "INFO:root:Training 10/286 done\n",
      "INFO:root:Training 11/286 done\n",
      "INFO:root:Training 12/286 done\n",
      "INFO:root:Training 13/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.3943, 0.4481]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2839, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.4596, 0.3781]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2990, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4264, 0.4924]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2857, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.4806, 0.4000]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2955, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4404, 0.5093]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2863, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 14/286 done\n",
      "INFO:root:Training 15/286 done\n",
      "INFO:root:Training 16/286 done\n",
      "INFO:root:Training 17/286 done\n",
      "INFO:root:Training 18/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.4930, 0.4133]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2936, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4500, 0.5136]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2831, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.4953, 0.4198]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2910, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4669, 0.5361]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2858, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.4926, 0.4090]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2960, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 19/286 done\n",
      "INFO:root:Training 20/286 done\n",
      "INFO:root:Training 21/286 done\n",
      "INFO:root:Training 22/286 done\n",
      "INFO:root:Training 23/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4668, 0.5191]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2769, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.4970, 0.4097]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2977, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4708, 0.5193]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2749, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5067, 0.4187]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2973, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4735, 0.5175]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2725, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 24/286 done\n",
      "INFO:root:Training 25/286 done\n",
      "INFO:root:Training 26/286 done\n",
      "INFO:root:Training 27/286 done\n",
      "INFO:root:Training 28/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5156, 0.4301]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2953, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4734, 0.5169]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2723, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5095, 0.4260]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2946, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4462, 0.4707]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2641, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5122, 0.4440]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2857, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 29/286 done\n",
      "INFO:root:Training 30/286 done\n",
      "INFO:root:Training 31/286 done\n",
      "INFO:root:Training 32/286 done\n",
      "INFO:root:Training 33/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4823, 0.5415]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2806, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5005, 0.4215]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2926, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4791, 0.5231]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2725, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5045, 0.4226]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2940, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4807, 0.5208]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2705, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 34/286 done\n",
      "INFO:root:Training 35/286 done\n",
      "INFO:root:Training 36/286 done\n",
      "INFO:root:Training 37/286 done\n",
      "INFO:root:Training 38/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5010, 0.4193]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2941, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4857, 0.5192]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2671, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.4927, 0.4056]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2980, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4918, 0.5191]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2639, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.4981, 0.4061]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.3004, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 39/286 done\n",
      "INFO:root:Training 40/286 done\n",
      "INFO:root:Training 41/286 done\n",
      "INFO:root:Training 42/286 done\n",
      "INFO:root:Training 43/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4928, 0.5138]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2606, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5016, 0.4122]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2986, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4906, 0.5068]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2582, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5109, 0.4221]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2975, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4876, 0.5040]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2583, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 44/286 done\n",
      "INFO:root:Training 45/286 done\n",
      "INFO:root:Training 46/286 done\n",
      "INFO:root:Training 47/286 done\n",
      "INFO:root:Training 48/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5124, 0.4255]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2963, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4876, 0.5052]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2589, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5107, 0.4289]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2935, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4883, 0.5053]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2586, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5051, 0.4257]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2925, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 49/286 done\n",
      "INFO:root:Training 50/286 done\n",
      "INFO:root:Training 51/286 done\n",
      "INFO:root:Training 52/286 done\n",
      "INFO:root:Training 53/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4897, 0.5071]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2588, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5056, 0.4269]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2920, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4909, 0.5097]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2595, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5076, 0.4299]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2913, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4930, 0.5085]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2578, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 54/286 done\n",
      "INFO:root:Training 55/286 done\n",
      "INFO:root:Training 56/286 done\n",
      "INFO:root:Training 57/286 done\n",
      "INFO:root:Training 58/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5076, 0.4307]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2908, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4780, 0.4991]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2608, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5109, 0.4379]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2885, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4739, 0.4916]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2593, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5092, 0.4429]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2848, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 59/286 done\n",
      "INFO:root:Training 60/286 done\n",
      "INFO:root:Training 61/286 done\n",
      "INFO:root:Training 62/286 done\n",
      "INFO:root:Training 63/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4885, 0.5094]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2606, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5045, 0.4366]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2860, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4928, 0.5148]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2611, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.4974, 0.4286]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2870, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 64/286 done\n",
      "INFO:root:Training 65/286 done\n",
      "INFO:root:Training 66/286 done\n",
      "INFO:root:Training 67/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4916, 0.5093]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2590, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5080, 0.4400]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2858, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4939, 0.5113]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2588, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5084, 0.4399]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2861, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 68/286 done\n",
      "INFO:root:Training 69/286 done\n",
      "INFO:root:Training 70/286 done\n",
      "INFO:root:Training 71/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4860, 0.5022]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2582, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5067, 0.4411]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2845, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4926, 0.5088]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2582, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5082, 0.4409]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2854, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4852, 0.5074]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2613, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 72/286 done\n",
      "INFO:root:Training 73/286 done\n",
      "INFO:root:Training 74/286 done\n",
      "INFO:root:Training 75/286 done\n",
      "INFO:root:Training 76/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5084, 0.4418]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2850, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4905, 0.5068]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2582, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5064, 0.4413]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2843, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4906, 0.5126]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2611, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5045, 0.4406]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2837, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 77/286 done\n",
      "INFO:root:Training 78/286 done\n",
      "INFO:root:Training 79/286 done\n",
      "INFO:root:Training 80/286 done\n",
      "INFO:root:Training 81/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4837, 0.5045]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2605, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5065, 0.4436]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2830, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4893, 0.5094]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2602, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5015, 0.4384]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2835, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4884, 0.5091]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2605, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 82/286 done\n",
      "INFO:root:Training 83/286 done\n",
      "INFO:root:Training 84/286 done\n",
      "INFO:root:Training 85/286 done\n",
      "INFO:root:Training 86/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5072, 0.4441]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2831, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4903, 0.5079]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2589, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5069, 0.4443]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2828, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4864, 0.5031]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2585, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5047, 0.4419]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2831, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 87/286 done\n",
      "INFO:root:Training 88/286 done\n",
      "INFO:root:Training 89/286 done\n",
      "INFO:root:Training 90/286 done\n",
      "INFO:root:Training 91/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4888, 0.5078]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2596, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5102, 0.4475]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2828, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4911, 0.5115]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2603, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5059, 0.4441]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2825, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4896, 0.5073]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2589, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 92/286 done\n",
      "INFO:root:Training 93/286 done\n",
      "INFO:root:Training 94/286 done\n",
      "INFO:root:Training 95/286 done\n",
      "INFO:root:Training 96/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5046, 0.4425]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2827, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4913, 0.5078]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2583, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5047, 0.4415]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2833, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4900, 0.5088]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2595, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5035, 0.4448]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2809, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 97/286 done\n",
      "INFO:root:Training 98/286 done\n",
      "INFO:root:Training 99/286 done\n",
      "INFO:root:Training 100/286 done\n",
      "INFO:root:Training 101/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4908, 0.5091]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2593, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5029, 0.4468]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2795, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4892, 0.5068]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2589, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.4984, 0.4416]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2801, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4922, 0.5085]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2582, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 102/286 done\n",
      "INFO:root:Training 103/286 done\n",
      "INFO:root:Training 104/286 done\n",
      "INFO:root:Training 105/286 done\n",
      "INFO:root:Training 106/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5013, 0.4439]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2802, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4923, 0.5086]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2582, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5027, 0.4459]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2799, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4945, 0.5086]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2571, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 107/286 done\n",
      "INFO:root:Training 108/286 done\n",
      "INFO:root:Training 109/286 done\n",
      "INFO:root:Training 110/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5071, 0.4486]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2806, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4954, 0.5052]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2549, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5055, 0.4466]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2809, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4908, 0.5033]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2563, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5083, 0.4480]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2815, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 111/286 done\n",
      "INFO:root:Training 112/286 done\n",
      "INFO:root:Training 113/286 done\n",
      "INFO:root:Training 114/286 done\n",
      "INFO:root:Training 115/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4941, 0.5067]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2563, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5046, 0.4465]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2805, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4879, 0.5025]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2574, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5037, 0.4488]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2788, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4908, 0.5055]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2574, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 116/286 done\n",
      "INFO:root:Training 117/286 done\n",
      "INFO:root:Training 118/286 done\n",
      "INFO:root:Training 119/286 done\n",
      "INFO:root:Training 120/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5047, 0.4486]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2794, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4929, 0.5067]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2570, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5105, 0.4524]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2803, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4926, 0.5061]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2568, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5095, 0.4546]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2785, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 121/286 done\n",
      "INFO:root:Training 122/286 done\n",
      "INFO:root:Training 123/286 done\n",
      "INFO:root:Training 124/286 done\n",
      "INFO:root:Training 125/286 done\n",
      "INFO:root:Training 126/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4932, 0.5073]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2571, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5006, 0.4456]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2790, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4950, 0.5097]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2574, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5036, 0.4476]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2793, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4911, 0.5051]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2570, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 127/286 done\n",
      "INFO:root:Training 128/286 done\n",
      "INFO:root:Training 129/286 done\n",
      "INFO:root:Training 130/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5040, 0.4487]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2790, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4925, 0.5054]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2565, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5064, 0.4529]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2779, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4959, 0.5077]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2559, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5063, 0.4519]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2784, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 131/286 done\n",
      "INFO:root:Training 132/286 done\n",
      "INFO:root:Training 133/286 done\n",
      "INFO:root:Training 134/286 done\n",
      "INFO:root:Training 135/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4960, 0.5068]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2554, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5068, 0.4500]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2797, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4947, 0.5040]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2546, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5016, 0.4493]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2775, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4923, 0.5028]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2553, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 136/286 done\n",
      "INFO:root:Training 137/286 done\n",
      "INFO:root:Training 138/286 done\n",
      "INFO:root:Training 139/286 done\n",
      "INFO:root:Training 140/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.4997, 0.4477]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2774, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4933, 0.5047]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2558, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5035, 0.4481]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2791, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4944, 0.5055]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2556, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5050, 0.4509]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2783, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 141/286 done\n",
      "INFO:root:Training 142/286 done\n",
      "INFO:root:Training 143/286 done\n",
      "INFO:root:Training 144/286 done\n",
      "INFO:root:Training 145/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4954, 0.5050]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2548, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5056, 0.4527]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2776, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4926, 0.5008]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2541, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5052, 0.4517]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2780, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4955, 0.5055]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2550, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 146/286 done\n",
      "INFO:root:Training 147/286 done\n",
      "INFO:root:Training 148/286 done\n",
      "INFO:root:Training 149/286 done\n",
      "INFO:root:Training 150/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5065, 0.4546]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2770, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4927, 0.5002]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2538, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5063, 0.4533]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2776, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4936, 0.5029]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2547, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 151/286 done\n",
      "INFO:root:Training 152/286 done\n",
      "INFO:root:Training 153/286 done\n",
      "INFO:root:Training 154/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5014, 0.4471]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2785, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4960, 0.5053]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2547, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5070, 0.4540]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2776, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4962, 0.5057]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2548, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 155/286 done\n",
      "INFO:root:Training 156/286 done\n",
      "INFO:root:Training 157/286 done\n",
      "INFO:root:Training 158/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5046, 0.4530]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2769, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4951, 0.5047]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2548, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5062, 0.4532]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2776, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4927, 0.5026]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2550, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5043, 0.4540]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2762, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 159/286 done\n",
      "INFO:root:Training 160/286 done\n",
      "INFO:root:Training 161/286 done\n",
      "INFO:root:Training 162/286 done\n",
      "INFO:root:Training 163/286 done\n",
      "INFO:root:Training 164/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4948, 0.5061]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2557, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5070, 0.4582]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2753, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4933, 0.5002]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2535, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5060, 0.4564]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2758, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4924, 0.4984]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2530, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 165/286 done\n",
      "INFO:root:Training 166/286 done\n",
      "INFO:root:Training 167/286 done\n",
      "INFO:root:Training 168/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5048, 0.4538]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2766, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4955, 0.5045]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2545, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5061, 0.4559]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2761, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4952, 0.5058]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2553, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5050, 0.4566]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2752, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 169/286 done\n",
      "INFO:root:Training 170/286 done\n",
      "INFO:root:Training 171/286 done\n",
      "INFO:root:Training 172/286 done\n",
      "INFO:root:Training 173/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4931, 0.5027]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2548, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5028, 0.4547]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2751, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4960, 0.5084]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2562, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5017, 0.4542]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2748, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4961, 0.5061]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2550, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 174/286 done\n",
      "INFO:root:Training 175/286 done\n",
      "INFO:root:Training 176/286 done\n",
      "INFO:root:Training 177/286 done\n",
      "INFO:root:Training 178/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5020, 0.4553]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2744, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4946, 0.5035]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2544, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5019, 0.4528]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2757, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4954, 0.5045]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2545, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5025, 0.4515]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2767, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 179/286 done\n",
      "INFO:root:Training 180/286 done\n",
      "INFO:root:Training 181/286 done\n",
      "INFO:root:Training 182/286 done\n",
      "INFO:root:Training 183/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4975, 0.5046]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2536, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5055, 0.4523]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2778, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4944, 0.5027]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2542, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5025, 0.4531]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2758, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4981, 0.5063]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2541, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 184/286 done\n",
      "INFO:root:Training 185/286 done\n",
      "INFO:root:Training 186/286 done\n",
      "INFO:root:Training 187/286 done\n",
      "INFO:root:Training 188/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5064, 0.4586]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2748, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4958, 0.5045]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2543, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5022, 0.4550]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2746, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4975, 0.5072]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2548, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5047, 0.4576]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2745, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 189/286 done\n",
      "INFO:root:Training 190/286 done\n",
      "INFO:root:Training 191/286 done\n",
      "INFO:root:Training 192/286 done\n",
      "INFO:root:Training 193/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4982, 0.5079]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2549, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5035, 0.4548]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2754, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4971, 0.5061]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2545, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5053, 0.4580]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2745, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4967, 0.5056]], grad_fn=<AddmmBackward>)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 194/286 done\n",
      "INFO:root:Training 195/286 done\n",
      "INFO:root:Training 196/286 done\n",
      "INFO:root:Training 197/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.2545, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5067, 0.4614]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2734, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4964, 0.5051]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2544, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5059, 0.4584]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2746, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 198/286 done\n",
      "INFO:root:Training 199/286 done\n",
      "INFO:root:Training 200/286 done\n",
      "INFO:root:Training 201/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4943, 0.5011]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2534, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5048, 0.4577]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2744, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4941, 0.5018]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2539, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5066, 0.4611]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2735, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4951, 0.5012]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2530, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 202/286 done\n",
      "INFO:root:Training 203/286 done\n",
      "INFO:root:Training 204/286 done\n",
      "INFO:root:Training 205/286 done\n",
      "INFO:root:Training 206/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5024, 0.4580]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2731, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4940, 0.5024]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2542, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5047, 0.4600]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2732, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4953, 0.5062]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2555, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5006, 0.4564]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2730, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 207/286 done\n",
      "INFO:root:Training 208/286 done\n",
      "INFO:root:Training 209/286 done\n",
      "INFO:root:Training 210/286 done\n",
      "INFO:root:Training 211/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4972, 0.5044]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2536, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5051, 0.4620]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2723, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4929, 0.4991]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2531, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5020, 0.4591]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2723, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4942, 0.5051]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2555, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 212/286 done\n",
      "INFO:root:Training 213/286 done\n",
      "INFO:root:Training 214/286 done\n",
      "INFO:root:Training 215/286 done\n",
      "INFO:root:Training 216/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5024, 0.4595]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2723, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4965, 0.5058]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2547, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5065, 0.4622]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2729, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4920, 0.4953]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2517, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5064, 0.4619]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2730, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 217/286 done\n",
      "INFO:root:Training 218/286 done\n",
      "INFO:root:Training 219/286 done\n",
      "INFO:root:Training 220/286 done\n",
      "INFO:root:Training 221/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4937, 0.5013]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2538, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5009, 0.4559]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2735, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4958, 0.5036]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2539, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5028, 0.4586]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2730, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4978, 0.5062]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2542, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 222/286 done\n",
      "INFO:root:Training 223/286 done\n",
      "INFO:root:Training 224/286 done\n",
      "INFO:root:Training 225/286 done\n",
      "INFO:root:Training 226/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5015, 0.4569]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2733, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4972, 0.5056]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2542, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5002, 0.4551]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2736, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4978, 0.5060]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2541, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5070, 0.4630]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2727, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 227/286 done\n",
      "INFO:root:Training 228/286 done\n",
      "INFO:root:Training 229/286 done\n",
      "INFO:root:Training 230/286 done\n",
      "INFO:root:Training 231/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4922, 0.4948]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2513, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5020, 0.4577]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2731, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4994, 0.5098]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2552, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5053, 0.4626]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2721, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 232/286 done\n",
      "INFO:root:Training 233/286 done\n",
      "INFO:root:Training 234/286 done\n",
      "INFO:root:Training 235/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4950, 0.5005]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2528, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5043, 0.4627]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2715, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4969, 0.5037]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2534, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5036, 0.4604]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2724, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4933, 0.4984]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2526, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 236/286 done\n",
      "INFO:root:Training 237/286 done\n",
      "INFO:root:Training 238/286 done\n",
      "INFO:root:Training 239/286 done\n",
      "INFO:root:Training 240/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5047, 0.4620]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2721, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4933, 0.4948]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2508, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5044, 0.4606]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2727, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4915, 0.4957]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2522, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5008, 0.4577]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2724, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 241/286 done\n",
      "INFO:root:Training 242/286 done\n",
      "INFO:root:Training 243/286 done\n",
      "INFO:root:Training 244/286 done\n",
      "INFO:root:Training 245/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4969, 0.5064]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2548, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5057, 0.4660]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2705, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.5001, 0.5117]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2559, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5029, 0.4616]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2714, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4979, 0.5054]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2538, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 246/286 done\n",
      "INFO:root:Training 247/286 done\n",
      "INFO:root:Training 248/286 done\n",
      "INFO:root:Training 249/286 done\n",
      "INFO:root:Training 250/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5038, 0.4620]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2716, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4893, 0.4898]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2504, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5081, 0.4691]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2700, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4922, 0.4963]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2521, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5068, 0.4692]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2693, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 251/286 done\n",
      "INFO:root:Training 252/286 done\n",
      "INFO:root:Training 253/286 done\n",
      "INFO:root:Training 254/286 done\n",
      "INFO:root:Training 255/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4947, 0.5027]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2540, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5038, 0.4678]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2685, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4888, 0.4926]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2520, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5065, 0.4723]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2675, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4864, 0.4883]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2511, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 256/286 done\n",
      "INFO:root:Training 257/286 done\n",
      "INFO:root:Training 258/286 done\n",
      "INFO:root:Training 259/286 done\n",
      "INFO:root:Training 260/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5080, 0.4746]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2671, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4922, 0.5021]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2550, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5028, 0.4685]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2676, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4934, 0.5079]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2573, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5018, 0.4675]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2677, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 261/286 done\n",
      "INFO:root:Training 262/286 done\n",
      "INFO:root:Training 263/286 done\n",
      "INFO:root:Training 264/286 done\n",
      "INFO:root:Training 265/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4940, 0.5059]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2559, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.4994, 0.4624]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2692, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4933, 0.5026]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2547, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5030, 0.4670]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2686, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4902, 0.4975]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2537, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 266/286 done\n",
      "INFO:root:Training 267/286 done\n",
      "INFO:root:Training 268/286 done\n",
      "INFO:root:Training 269/286 done\n",
      "INFO:root:Training 270/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5019, 0.4671]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2680, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4933, 0.5015]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2541, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.4996, 0.4620]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2695, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4933, 0.5025]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2546, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 271/286 done\n",
      "INFO:root:Training 272/286 done\n",
      "INFO:root:Training 273/286 done\n",
      "INFO:root:Training 274/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5038, 0.4641]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2705, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4956, 0.5043]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2543, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.4988, 0.4575]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2716, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4964, 0.5081]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2559, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5001, 0.4616]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2700, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 275/286 done\n",
      "INFO:root:Training 276/286 done\n",
      "INFO:root:Training 277/286 done\n",
      "INFO:root:Training 278/286 done\n",
      "INFO:root:Training 279/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]])\n",
      "tensor([[0.4982, 0.5095]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2557, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.4996, 0.4601]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2706, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4945, 0.4994]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2524, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5016, 0.4602]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2715, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4960, 0.5028]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2534, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 280/286 done\n",
      "INFO:root:Training 281/286 done\n",
      "INFO:root:Training 282/286 done\n",
      "INFO:root:Training 283/286 done\n",
      "INFO:root:Training 284/286 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[0.5038, 0.4665]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2692, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4964, 0.5045]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2540, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5082, 0.4706]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2692, grad_fn=<MseLossBackward>)\n",
      "tensor([[1., 0.]])\n",
      "tensor([[0.4920, 0.4973]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2527, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1.]])\n",
      "tensor([[0.5064, 0.4735]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.2668, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training 285/286 done\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "trainLog = logging.getLogger()\n",
    "\n",
    "# Training Loop\n",
    "\n",
    "for k in range(len(vsInput)):  \n",
    "    \n",
    "    vs, target = vsInput[k]\n",
    "    \n",
    "    vs_n = (vs+80)/80\n",
    "    \n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    input = vs_n.view(-1,1,256,256)\n",
    "    output = net(input)\n",
    "    print(target)\n",
    "    print(output)\n",
    "    loss = criterion(output, target)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()    # Does the update\n",
    "    info = \"Training \" + str(k)+\"/\"+str(len(vsInput))+\" done\"\n",
    "    trainLog.info(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
